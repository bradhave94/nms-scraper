---
description: Project overview and architecture
---

# No Man's Sky Wiki Scraper Project

This project scrapes data from the No Man's Sky wiki and organizes it into structured JSON files and SQLite database.

## Project Structure

```
nms-scraper/
├── nms_scraper.py          # Main scraper (class: NMSScraper)
├── nms.db                  # SQLite database
├── requirements.txt        # Dependencies
├── data/                   # Generated JSON files
├── extractors/             # Recipe extractors
│   ├── nutrient_processor_extractor.py
│   └── refinery_extractor.py
└── categories/             # Category generation tools
    ├── generate_categories.py
    └── generated_categories.py
```

## Core Architecture

- **Main Scraper**: [nms_scraper.py](mdc:nms_scraper.py) - Content-based classification with sequential IDs
- **Database**: `nms.db` - SQLite database storing all scraped items
- **Recipe Extractors**: Located in `extractors/` folder
  - [extractors/refinery_extractor.py](mdc:extractors/refinery_extractor.py) - Extracts refinery recipes
  - [extractors/nutrient_processor_extractor.py](mdc:extractors/nutrient_processor_extractor.py) - Extracts cooking recipes
- **Category Discovery**: Located in `categories/` folder

## Target Output Files

The scraper generates these JSON files in the `data/` directory:
- `Buildings.json` - Base building components
- `Cooking.json` - Food and cooking items
- `Curiosities.json` - Rare artifacts and curiosities
- `Fish.json` - Aquatic creatures
- `NutrientProcessor.json` - Cooking recipes (recipe format)
- `Others.json` - Miscellaneous items
- `Products.json` - Manufactured products
- `RawMaterials.json` - Basic resources
- `Refinery.json` - Refinery recipes (recipe format)
- `Technology.json` - All technology items
- `Trade.json` - Trade commodities

## Key Design Principles

1. **Sequential IDs**: Items use sequential IDs (cook1, cook2, prod1, tech1, etc.) instead of name-based IDs
2. **Content-based Classification**: Items are classified by analyzing their infobox, description, and usage patterns
3. **Recipe Structure**: Refinery and NutrientProcessor use structured recipe format with lowercase fields:
   ```json
   {
     "id": "nut1",
     "inputs": [{"id": "cook1", "name": "Item Name", "quantity": 1}],
     "output": {"id": "cook2", "name": "Output Name", "quantity": 1},
     "time": "2.5",
     "operation": "Processor Setting: Combining"
   }
   ```
4. **Missing Ingredient Handling**: Uses placeholder IDs (missing_item_name) for ingredients not in database
5. **SQLite Integration**: All data stored in database with JSON export capability
6. **Rate Limiting**: Configurable delays between API requests
7. **Pagination Support**: Handles categories with >500 items via API continuation
8. **Hard Reset**: `--hard-reset` flag to delete database and data folder for clean runs
9. **Auto Recipe Extraction**: `--extract-recipes` flag to automatically run recipe extractors after scraping
10. **Comprehensive Recipe Coverage**: Extracts 350+ refinery recipes from all items in database

## Critical Categories

The scraper must include these important categories to ensure complete recipe coverage:
- **Harvested Agricultural Substance**: Contains Faecium, Frost Crystal, etc. with many refinery recipes
- **Flora elements**: Plant-based resources used in refining
- **Minerals**: Various mineral resources used in refining
- **Earth elements**: Basic elements used in many recipes

## Recipe Template Formats

1. **Refinery Recipes**: Uses `{{PoC-Refine}}` template
   ```
   {{PoC-Refine
   | Mordite,3;1;0.24%Assisted Decomposition
   | Di-hydrogen,1;Carbon,1;1;0.08%Assisted Decomposition
   | Faecium,1;Oxygen,1;3;0.36%Oxygenate Microbes
   }}
   ```

2. **Nutrient Processor Recipes**: Uses `{{Cook}}` template
   ```
   {{Cook
   | Wailing Batter,1 + Grahj'am,1 + Cream,1 → Appalling Jam Sponge,1 ("Assemble Baked Product", 2.5)
   | Wailing Batter,1 + Furball Jelly,1 + Cream,1 → Appalling Jam Sponge,1 ("Assemble Baked Product", 2.5)
   }}
   ```