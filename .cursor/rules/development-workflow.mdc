---
description: Development workflow and debugging practices
---

# Development Workflow and Debugging

## Scraping Workflow

### 1. Category Discovery
```bash
python3 generate_categories.py
```
- Explores wiki category hierarchy
- Generates comprehensive category lists
- Outputs to `generated_categories.py`

### 2. Main Scraping Process
```bash
# Normal run with limit
python3 nms_scraper.py --limit 100

# Clean slate run (deletes database and data folder)
python3 nms_scraper.py --hard-reset --limit 50

# Full production run
python3 nms_scraper.py --hard-reset --limit 0
```
- Scrapes all items from discovered categories
- Uses content-based classification with sequential IDs
- Stores in SQLite database (`nms.db`)
- Exports to JSON files in `data/` directory

### 3. Recipe Extraction
```bash
cd extractors

# Extract nutrient processor recipes (default paths)
python3 nutrient_processor_extractor.py

# Extract refinery recipes (default paths)
python3 refinery_extractor.py

# With custom settings
python3 nutrient_processor_extractor.py --limit 50
python3 refinery_extractor.py --delay 0.5
```
- Extracts structured recipe data with lowercase fields
- Cross-references sequential IDs from main database
- Preserves missing ingredients with placeholder IDs
- Generates recipe JSON files in `../data/` directory

## Rate Limiting Best Practices

- **Default delay**: 0.5 seconds between requests
- **Heavy scraping**: 1.0+ seconds for large operations
- **Testing**: 0.1 seconds for small test runs
- Always use `--delay` parameter for control

## Debugging Common Issues

### API Pagination
- Categories with >500 items need continuation tokens
- Use `cmcontinue` parameter for subsequent requests
- Log progress for large categories

### Database Consistency
- Always use single database: `nms.db`
- Check table existence before queries
- Verify item IDs exist before recipe extraction

### Wiki Markup Parsing
- Test regex patterns with actual wiki content
- Handle special characters and templates
- Skip malformed or incomplete entries

### Classification Accuracy
- Review misclassified items in output files
- Adjust keyword matching in `classify_item`
- Add new classification rules as needed

## Testing and Validation

### Small Test Runs
```bash
# Test with clean slate
python3 nms_scraper.py --hard-reset --limit 10

# Quick test without reset
python3 nms_scraper.py --limit 10 --delay 0.1
```

### Database Inspection
```bash
sqlite3 nms.db "SELECT COUNT(*) FROM items GROUP BY group_name;"
```

### JSON Validation
Check output files for proper structure and expected content.